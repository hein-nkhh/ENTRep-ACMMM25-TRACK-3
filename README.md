# ENTRep-ACMMM25-TRACK-3: KGER: A Knowledge-Grounded Endoscopic Retrieval Framework with a Fused Bi-Encoder and Gemini Re-ranking Pipeline

## ‚ú® Overview

This project presents **KGER (Knowledge-Grounded Endoscopic Retrieval)**, a multi-stage framework designed to tackle the retrieval of endoscopic images in ENT (Ear-Nose-Throat) domain. KGER effectively combines **deep metric learning**, reasoning capabilities of **Large Multimodal Models (LMM)** like Gemini, and a smart score fusion strategy.

The system begins with **10 model NanoCLIP** (Kfold) architecture to quickly retrieve candidate images. Then, an advanced re-ranking phase uses **Gemini** to analyze and reason about the images, overcoming surface-level visual similarity limitations. Finally, the **Pos-Fuse** strategy fuses scores from both stages to ensure results are both visually intuitive and clinically accurate. KGER achieves state-of-the-art performance on the ENTRep dataset, bridging semantic gaps and providing a powerful tool for ENT applications.

---

## üìÅ Project Structure

```
.
‚îú‚îÄ‚îÄ requirements.txt             # Th∆∞ vi·ªán Python
‚îú‚îÄ‚îÄ config.py                   # Thi·∫øt l·∫≠p chung
‚îú‚îÄ‚îÄ .env                        # (tu·ª≥ ch·ªçn) bi·∫øn m√¥i tr∆∞·ªùng
‚îú‚îÄ‚îÄ blacklist_builder/          # T·∫°o blacklist t·ª´ d·ªØ li·ªáu b√°o ch√≠
‚îÇ   ‚îî‚îÄ‚îÄ blacklist_builder_app.py
‚îÇ   ‚îî‚îÄ‚îÄ builder/
‚îú‚îÄ‚îÄ llm_model/                  # G·ªçi v√† s·ª≠ d·ª•ng m√¥ h√¨nh LLM
‚îú‚îÄ‚îÄ utils/                      # Ti·ªán √≠ch d√πng chung
‚îú‚îÄ‚îÄ dynamodb/                   # T∆∞∆°ng t√°c v·ªõi DynamoDB
‚îú‚îÄ‚îÄ mongodb/                    # T∆∞∆°ng t√°c v·ªõi MongoDB
‚îú‚îÄ‚îÄ agent/                      # Backend API agent ƒë·ªÉ truy v·∫•n
‚îÇ   ‚îî‚îÄ‚îÄ app.py
‚îú‚îÄ‚îÄ Frontend/                   # Giao di·ªán ng∆∞·ªùi d√πng
    ‚îú‚îÄ‚îÄ package.json
    ‚îî‚îÄ‚îÄ ...
```

---

## üõ†Ô∏è System Requirements

- Python >= 3.10
- pip

---

## üß™ Python Environment Setup

```bash
# T·∫°o m√¥i tr∆∞·ªùng ·∫£o
python -m venv venv

# K√≠ch ho·∫°t
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# C√†i ƒë·∫∑t th∆∞ vi·ªán
pip install -r requirements.txt
```

---

## üß± Execution Steps

After setting up the environment, follow these steps to run the project:

### Step 1Ô∏è‚É£: Prepare Data
```bash
python -m scripts.prepare_data
```
- Prepare **training**, **validation**, and **test** datasets from the `data` folder.
- Output location: `./data/dataset`

### Step 2Ô∏è‚É£: Train NanoCLIP Model
```bash
python -m scripts.train
```
- Fine-tune the model using K-Fold cross-validation to generate checkpoints.
- Checkpoints saved at: `./checkpoint/nano_clip/logs`

### Step 3Ô∏è‚É£: Download and Extract Test Dataset
```bash
python -m scripts.download_and_extract_dataset
```
-  Download and extract test images for retrieval experiments.
-  Output saved at: `./data/downloaded_files`

### Step 4Ô∏è‚É£: Initial Image Retrieval
```bash
python -m scripts.infer_retrieval
```
- Perform initial retrieval to get the top 5 candidate images based on the input query.
- Results saved at: `./data/result`

### Step 5Ô∏è‚É£: Re-rank Results
```bash
python -m scripts.rerank_posfuse
```
-  Use the **Pos-Fuse** strategy combined with the **Gemini** model to re-rank the results from Step 4, producing the final ranked list.
-  Re-ranked results saved at: `./data/rerank_posfuse_result`
